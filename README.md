# MIT FutureMakers Program
The MIT FutureMakers Create-a-Thon is a Two-Step Artificial Intelligence Fellowship dedicated to diversifying the landscape of AI and the leaders behind it. [SureStart](https://mysurestart.com/) has partnered with the [MIT RAISE (Responsible AI for Social Empowerment and Education) Initiative](https://raise.mit.edu/) to select high achieving students with a diversity of experiences and perspectives, and develop their skills in Machine Learning and Product Development. Here's how:

**TRAIN** | In the first phase of the program, students learn AI skills through a curated, interest-led, self-paced curriculum, accessed virtually. Students are supported with one-on-one and group mentoring from experienced mentors who share knowledge, and provide accountability and encouragement.

**BUILD** | Then, it’s time to put those skills to work! In the second phase, students are placed into small teams to develop AI-based solutions to real-world problems with the support of a dedicated team mentor. The final projects are showcased in a virtual global Makeathon hosted by SureStart. 

<p align="center">
  <img width="500" src="https://user-images.githubusercontent.com/87036439/127762590-b9dea174-eacd-4846-b36f-005fc0f62256.png" alt="SureStart+Community+Lifecycle">
</p>

<p align="center">
  Following is a detailed account of the projects and lesson plans I completed over the course of the program.
</p>

## Table of Contents
**WEEK 1 | THE BASICS**

**[Day 1 | What I Hope To Learn](#day-1--what-i-hope-to-learn--toc)**<br>
**[Day 2 | Dr. David Kong | Leadership & Storytelling](#day-2--dr-david-kong--leadership--storytelling--toc)**<br>
**[Day 3 | Introduction to Machine Learning & Scikit-Learn](#day-3--introduction-to-machine-learning--scikit-learn--toc)**<br>
**[Day 4 | Deep Learning in Real World Problems](#day-4--deep-learning-in-real-world-problems--toc)**<br>

**WEEK 2 | CNNS, DATA & MACHINE LEARNING**

**[Day 7 | The Nature & Capacity of Tensorflow](#day-7--the-nature-and-capacity-of-tensorflow--toc)**<br>
**[Day 8 | What Are Neural Networks?](#day-8--what-are-neural-networks--toc)**<br>
**[Day 9 | Introduction to Convolutional Neural Networks](#day-9--introduction-to-convolutional-neural-networks--toc)**<br>
**[Day 10 | Algoeithm Bias & Data Sets](#day-10--algorithm-bias--data-sets--toc)**<br>
**[Day 11 | Neural Network Layers & MNIST Digit Practice](#day-11--neural-network-layers--mnist-digit-practice--toc)**<br>

**WEEK 3 | FUNCTIONS AND PREDICTIONS**

**[Day 14 | Loss Functions](#day-14--loss-functions--toc)**<br>
**[Day 15 | Activation Functions](#day-15--activation-functions--toc)**<br>
**[Day 16 | Ethics-Driven Machine Learning](#day-16--ethics-driven-machine-learning-practive--toc)**<br>
**[Day 17 | Image Classification & Machine Learning](#day-17--image-classification--machine-learning--toc)**<br>
**[Day 18 | Data Overfitting & Regularization](#day-18--data-overfitting--regularization--toc)**<br>

**WEEK 4 | APPLICATIONS OF MACHINE LEARNING**

**[Day 21 | Upsampling & Autoencoding](#day-21--upsampling--autoencoding--toc)**<br>
**[Day 22 | Affective Computing](#day-22--affective-computing--toc)**<br>
**[Day 23 | Natural Language Processing](#day-23--natural-language-processing--toc)**<br>
**[Day 24 | Computer Vision](#day-24--computer-vision-cv--toc)**<br>
**[Day 25 | Getting Ready for the Create-A-thon](#day-25--getting-ready-for-the-create-a-thon--toc)**<br>
 
 **INDEX**
 
 **[A. Cheat Sheets](#a-cheat-sheets--toc)**<br>
 **[B. Libraries](#b-libraries--toc)**<br>
 **[C. Articles](#c-articles--toc)**<br>
 **[D. Videos](#d-videos--toc)**<br>

# WEEK 1 | THE BASICS

## Day 1 | What I Hope To Learn | **[TOC](#table-of-contents)**<br>
### 7/6/2021

### Action Item : 
Create a section in your README or wiki called Responses to add reflections or answers for each activity. Remember to mark each response with the associated date. For Day 1’s reflection, reflect on what you hope to learn in this program.

### Reflection : 
One of the main reasons I am here is because I am afraid of computer scienc. I always have been. Since attending my first coding course at Berkeley, I've struggled immensely not only with the involved logic of computer programming, but mustering the curiosity necessary to solve the puzzles programming is embedded in. I suppose failing that first course may have also had something to do with that. It's been a thorn in my side for a quite a while now, and each time some new overzealous engineering professor wants to assign coding homework problems, I get anxious and and mentally unhinged. I'm afraid of coding. I'm afraid of how much I don't know, of being the weakest link in group projects, and afraid that I am not smart enough to not only engage with the material but to master it. So when I saw the opportunity to work with MIT Raise and Surestart this summer, I sought to change how I felt. 

In this program I hope to learn the basic fundamentals of computer programming in Python. I am striving to establish mental tools and templates on how to approach problem sets from a computer's logical perspective, and understand how to redesign alternative (optimized) routes to solve problems and improve my default methodologies. Furthermore, I hope to learn how to balance my dependency on others with my own contribution to group work. I tend to overthink, hit roadblocks, ask for help, and eventually just copy for all intents and purposes. I want to contribute more than another another mouth to feed, and I am hoping that Surestart can teach me how. 

In addition to my self edification and anxiety, I also hope to improve my ability to code in the context of animation. As an aspiring animation producer, I understand that one of the default coding languages for studio software is Python, and that it is necessary to understand how to design in Python just as much as it is with pencil. I am here to establish a sense of direction and possibility for myself as an animator and storyteller, and improve my versatility in storytelling as much as possible.

### Helpful Resource
Used the following guide to establish a fundamental understanding of Python. Check out this [handbook](https://www.pythonlikeyoumeanit.com/)!

## Day 2 | Dr. David Kong | Leadership & Storytelling | **[TOC](#table-of-contents)**<br>
### 7/7/2021

### Who is Dr. David Kong?
Director, Community Biotechnology Initiative
Research Scientist

David Sun Kong, Ph.D. is a Synthetic Biologist, community organizer, musician, and photographer based in Lexington, MA.  He is the Director of the MIT Media Lab's new [Community Biotechnology Initiative](https://www.media.mit.edu/groups/community-bio/overview/). Their mission: Empowering communities through biotechnology.

David conducted his graduate studies at MIT’s Media Lab, receiving a Master's degree for developing technology for printing nanostructures with energetic beams and a Ph.D. for demonstrating the first gene synthesis in a microfluidic (“lab-on-a-chip”) system. He was recognized as an emerging leader in synthetic biology as a "LEAP" fellow, served as a guest faculty member at the Marine Biology Lab in Woods Hole, MA, and is co-founder and managing faculty of "How To Grow (Almost) Anything," an international course on synthetic biology. He founded and chaired new Microfluidic and Hardware Tracks for the [International Genetically Engineered Machines Competition (iGEM)](https://igem.org/Main_Page) and is the official iGEM DJ. He was Technical Staff in the Bioengineering Systems & Technologies group at MIT’s Lincoln Laboratory and a founding member of the synthetic biology team.

He has also worked as a community organizer for more than a decade and is the founder of [EMW](http://www.emwbookstore.com/), an art, technology, and community space in Cambridge, MA. EMW's mission is to empower communities through the transformative power of artistic expression. We emphasize serving marginalized communities and develop all of our programming with values rooted in social justice. Our community programs explore expressive forms ranging from poetry to electronic music, beatboxing to bio-hacking and more.

### Action Item:
For Day 2’s reflection, reflect on what you learned in Dr. David Kong’s leadership seminar about yourself, the world, and what are your unique contributions to your local and global community.

### Reflection: 
Dr. Kong affirmed that I am on the right path in my life. When sharing my story of growth and personal acceptance, I aimed to create a narrative that was new in its composition. I've lievd through all the details myself, and have even shared my thoughts about my journey in other ways before to close friends. But working with Dr. Kong, I chose to present the information using his storytelling methods (challenge, choice and outcome) to complete strangers, and it not only deepened my comprehension of self, but it reminded me how much I enjoy the unnnerving complete vulnerability can cause. After I shared, the back of knees were drenched. I was scared but exhilerated to have the opportunity to give my testimony to the room in a new way, and I felt utterly fulfilled after I did. I love storytelling. I love how it unites people, how it cultivates a hunger for groundedness and embraces reflexivity, and how it shows people themselves--sometimes raw and imperfect. I want to create stories in animation and theme park design that do the same. Dr. Kong helped affirm that. 

I believe my purpose is to bring messages of humanity to people, intergenerationally. I feel my purpose lies within entertainment, with networking, with world building and character designing. There is no better feeling than impregnanting a thought with elements of your own character and sense of self, and having people embrace it firsthand. Dr. Kong mentioned that it is possible to share narratives with others as a conduit for conveying purpose. For me, that is the only way I _can_ do it. Who I am is a composition of the expereinces and teachings I've been blessed with, and the only way I have learned to unconver my purpose within my composition, is to unearth myself to others. 

Those continuous efforts enlightened me on how impactful my story, my presence, and my voice all really are. When I share my life, I feel validated, seen, uplifted and encouraged. And then I realized that my purpose was to _continue sharing_. And I began to see how much of a difference it makes--from the people I surround myself with, to the way I perceive the world, to what others find possible in their lives that once may not have been. The manifestation of my implicit truths have garnered beautiful experiences for me 10x over, and it is my purpose to share my wealth with the rest of the world. So that's exactly what I'm going to do. 

<p align="center">
  <img width="600" height="400" src="https://user-images.githubusercontent.com/87036439/127763586-bf5b5f66-44fe-4e50-82b3-20c2f7b0f47b.gif" alt="tell-a-story-guide-promo-superJumbo-v4">
</p>

### Helpful Resource
Continued to use the following guide to establish a fundamental understanding of Python. Check out this [handbook](https://www.pythonlikeyoumeanit.com/)!

## Day 3 | Introduction to Machine Learning & Scikit-Learn | **[TOC](#table-of-contents)**<br>
### 7/8/2021

### Lesson Plan: 
Reviewed Machine Learning Models & Algorithms using this [article](https://www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer). Scikit-Learn library uses NumPy, SciPy, and matplotlib libraries to implement machine learning algorithms.

### Action Item: 
1. Used this [Simple Model Development Activity](https://towardsdatascience.com/an-introduction-to-scikit-learn-the-gold-standard-of-python-machine-learning-e2b9238a98ab) to familiarize myself with Scikit-Learn.

2. Post short answers to the following questions:
  
  A. What is the difference between supervised and unsupervised learning?
  
  B. Describe why the following statement is FALSE: Scikit-Learn has the
power to visualize data without a Graphviz, Pandas, or other data
analysis libraries.

### Reflection:
1. What is the difference between supervised and unsupervised learning?

(A) Supervised Learning is a type of ML that incorporates labels (classes) within the training data as it input into the algorithm. Additionally, Supervised Learning provides feedback to the computer directly to assist it in its ability to predict correct outcomes. This is primarily used in elements of Regression & Classification Models.
Unsupervised Learning incorporates training data without any labels or classes. Additionally, there is no external feedback on whether the predictions or actions it is performing are correct. Instead, the machine must learn from patterns whether or not it is functioning appropriately. In order to achieve this, we use clustering do showcase the similarities between multiple features that can be used to identify patterns in the algorithm.

2. Describe why the following statement is FALSE: Scikit-Learn has the power to visualize data without a Graphviz, Pandas, or other data analysis libraries.

(A) The Scikit-Learn program is an open source library that is built on Pandas and other data analysis libraries. In fact, it was designed specifically for data mining and analysis such as feature extraction & normalizaition, regression, clustering, etc. It needs analysis libraries in order to achieve this functionality.

### Supplemental Activity: [ADD]
Designed a Machine Learning Model using a [ML Kaggle Activity](https://www.kaggle.com/dansbecker/your-first-machine-learning-model)

## Day 4 | Deep Learning in Real World Problems | **[TOC](#table-of-contents)**<br>
### 7/9/2021

### Lesson Plan:
Approached a high-level understanding of Deep Learning models & algorithms using this [article](https://serokell.io/blog/deep-learning-and-neural-network-guide).

### Action Item:
Think about a real-world problem and see if you can find a dataset that has the characteristics of the data of that problem. Then, think about the deep learning algorithm that you would likely use to develop a solution to it. Outline why you picked a particular approach and share the dataset.

### Reflection:
(Problem) COVID-19 Propogation based on racial diversity in America. There has been confirmation that members of low-income, mainly black, neighborhoods are disproportionately affected by the SarsCoV2 virus since its discovery back in 2019. Using a section of historical positive case data and population denisty data (compartmentalized by race), it may be possible to train an algorithm to predict which cities are at highest risk, ordered by race. This is not to prioritize any race over another, but rather to showcase a potentially systemic flaw in health care distribution, environmental conditions in urban and rural areas, and which communities suffer from preexisting conditions. Understanding these patterns and correlations may help hospitals allocate medical resources, remote service locations, vaccine resources, and more. 

I'm not too sure the best algorithm to apply for this type of project, however I would wager either Support Vector Machines or Decision Trees may be most beneficial for this task. The SVM algorithm is a supervised machine learning algorithm which can be used for both classification or regression challenges. Apparently it is mostly used in classification problems. SVM transforms the data base on it, finds an optimal boundary between the possible outputs. 

The SVM Algorithm
1. Define an optimal hyperplane with a maximized margin
2. Map data to a high dimensional space where it is easier to classify with linear decision surfaces
3. Reformulate problem so that data is mapped implicitly into this space

SVM has been used consistently in Bioinformatics to classify proteins, genes, malignant cells, etc. Understanding that, I think it shows promise for classifying positive test subjects and compartmentalizing them by location, yielding predictive analytics for labeled categories. 

I also think Decision Trees may also be a promising algorithm. A decision tree is a decision support tool that uses a tree-like model of decision-making process and the possible consequences. It covers event outcomes, resource costs, and utility of decisions. Decision Trees resemble an algorithm or a flowchart that contains only conditional control statements. This could be a beneficial model for outlining allocation of resourcesm based on concentration of positive testing  individuals within a limited radius. 

[CRDT Data - CRDT.zip](https://github.com/MatthewMZN/FutureMakers/files/6852183/CRDT.Data.-.CRDT.zip)
https://demographics.coopercenter.org/racial-dot-map#thedata

### Supplemental Activity
Using the following article, I learned the distinction between Artificial Intelligence, Machine Learning, and Deep Learning. [Check it out](https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/)!

### Quick Dive Into the Ethics of AI: 
I read about some of the ethical concerns discussed when applying or using Machine Learning. This is a helpful resource when generating ideas for public use and other future projects. [Check it out](https://towardsdatascience.com/ethics-in-machine-learning-9fa5b1aadc12)!

# WEEK 2 | CNNS, DATA & MACHINE LEARNING
## Day 7 | The Nature and Capacity of TensorFlow | **[TOC](#table-of-contents)**<br>
### 7/12/2021

### Lesson Plan:
Familiarized myself with multiple Deep Learning Libraries.

1. [TensorFlow Library](https://www.datacamp.com/community/tutorials/tensorflow-tutorial) | An open source library for numerical computation “using data flow graphs” created by Google, which is predominantly used to implement complex machine and deep learning algorithms.
2. [Keras Library](https://www.datacamp.com/community/tutorials/deep-learning-python?utm_source=adwords_ppc&utm_campaignid=1658343521&utm_adgroupid=63833880615&utm_device=c&utm_keyword=keras&utm_matchtype=p&utm_network=g&utm_adpostion=&utm_creative=319519154328&utm_targetid=aud-299261629654:kwd-295071417107&utm_loc_interest_ms=&utm_loc_physical_ms=9016565&gclid=CjwKCAiAxp-ABhALEiwAXm6IyQJo6LA_Z4HlQUiBhrfFwOFL3Vu0bDTjMI53og6hcZfeWIkzEZRBTxoCzbkQAvD_BwE) | 

### Action Item:
Write about or record a video of yourself answering the following questions:

1. What are "Tensors" and what are they used for in Machine Learning?
2. What did you notice about the computations that you ran in the TensorFlow programs (i.e. interactive models) in the tutorial?

### Reflection:
1. What are “Tensors” and what are they used for in Machine Learning?

(A) Right off the bat, the tutorial states that "tensors" are multidimensional data arrays. Thinking aloud as I type, I'd say such arrays seem to be combinations of basis/unit vectors and components of a specific coordinate system within a vector space. Like a vector, tensors represent "objects" using mathametical relationships between said objects and the coordniate systems/vector space they exist in. Tensors subsume vectors as representational objects that define other algebraic object, vectors, or other tensors, as they are  ahigher order function that are represented using an array of numbers that are a function of "dimensional space x rank(dimension of the vector space generated by its columns). In short, tensors are algebraic representations of unit vectors and vector space components in the form of data that represent the multidimensional orientation of another object within a vector space.

2. What did you notice about the computations that you ran in the TensorFlow programs (i.e. interactive models) in the tutorial?

(A) I suppose that all of the outputs printed in the interactive models were in the form of arrays. I noticed that the multiplication of the x1, x2 variables in the model produced a 1x4 row vector, with each element as the multiplicative result of the same elements in each array. So, is this to say that algebraic operations on tensors will always result in tensors? Other operations could potentially yield other classes of tensors, like scalars, should the rank of the array go to zero. What's also interesting is that the tutotrial claims that interactive sessions need to be ran in order for the quantifiable values of tensors to be printed, however in Google Colab the values are automatically printed without need to initialize a sesison. The information is printed alongside the arrays. 

The other computations regarding the transformation of the image data set was light, if that. Mainly the tutorial presented various ways to extract features and standardize image sizes, but other than that there weren't any noticeable computations that I was aware of. 

### Supplemental Activity: [ADD]
Used a TensorFlow [Jupyter Notebook](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition) to learn how to recognize Human Activity using smartphone sensor data.

## Day 8 | What Are Neural Networks? | **[TOC](#table-of-contents)**<br>
### 7/13/2021

### Lesson Plan:
Review [this guide](https://serokell.io/blog/deep-learning-and-neural-network-guide) to learn about the common components of Neural Networks, and how they work with different ML functions and algorithms.

<p align="center">
  <img width="800" src="https://user-images.githubusercontent.com/87036439/127758389-e428a5ba-5b1c-42d0-8804-9405d16b0eae.PNG" alt="NN">
</p>

### Action Item:
Use what you learned in the article above (i.e. Neuron, Weights, Bias, Functions, Sigmoid, Softmax, Input vs Output, etc) to develop a NN model using this [Kaggle Notebook](https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection). If you need some scaffolding code to get started, check out the “Code” tab on the shared link and select a recent Gold/Silver medal-ed notebook. Feel free to examine different notebooks to see different model topologies and select one that you find the most interesting or even explore combining them. 

### Reflection: [ADD]

## Day 9 | Introduction to Convolutional Neural Networks | **[TOC](#table-of-contents)**<br>
### 7/14/2021

### Lesson Plan: 
1. Learned about Convolutional Nearual Networks (CNNs) using [this notebook](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks).
2. Used this [link](https://www.cs.ryerson.ca/~aharley/vis/conv/flat.html) to visualize how CNNs work with handwritten digits. It link to platform that gives detailed visuals showcasing how a machine can correctly guess the value of hand drawn digits.
3. Learned about Confusion Matrices in Machine Learning [here](https://machinelearningmastery.com/confusion-matrix-machine-learning/).

### Action Item:
Review this [Kaggle tutorial](https://www.kaggle.com/kanncaa1/convolutional-neural-network-cnn-tutorial). Extend the training data using the full training data from this [MNIST Database](http://yann.lecun.com/exdb/mnist/). Evaluate the model performance (hint: look at the confusion matrices) applied to the same test-set in comparison to the performance reported in the original Kaggle Tutorial Notebook.

### Reflection: [ADD]

### Supplemental Activity:
Review the thinking behind the convolution operation and how the operation is carried out using CNNs with this [article](https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/). 

## Day 10 | Algorithm Bias & Data Sets | **[TOC](#table-of-contents)**<br>
### 7/15/2021

### Lesson Plan:
Review the Stanford and Google AI [interactive presentation](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/slides/cs224n-2019-lecture19-bias.pdf) about algorithmic bias with vision and language applications of AI.

### Action Item:
Play “Survival of the Best Fit'' to learn more about how AI might impact human resources and hiring processes in different fields. When you have completed this game, answer the following questions:

1. How do you think Machine Learning or AI concepts were utilized in the design of this game?
2. Can you give a real-world example of a biased machine learning model, and
share your ideas on how you make this model more fair, inclusive, and
equitable? Please reflect on why you selected this specific biased model.

### Reflection: [ADD]

### Supplemental Material: 
Reviewed a short [video](https://www.youtube.com/watch?v=yqIpPwkpXXc) that explains the significance of considering Diversity, Equity & Inclusion in different environments, such as society, online spaces, school, work, etc.

### A Dive into Ethics: 
It's important understand that the AI and automated systems we train could potentially, likely accidentally, "learn" to be biased. Read this [article](http://gendershades.org/overview.html) and discuss some of the ways algorithms can be biased, and ways to avoid bias when constructing AI projects. 

### Reflection: [ADD]

## Day 11 | Neural Network Layers & MNIST Digit Practice | **[TOC](#table-of-contents)**<br>
### 7/16/2021

### Lesson Plan: 
1. Refer to the [CNN Architecture](https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939) guide and familiarize yourself with the different layers (i.e. Convolution layer, Pooling, and Fully Connected). Think critically about what each of these layers do.
2. Complete this [introductory dataset practice](https://medium.com/tebs-lab/how-to-classify-mnist-digits-with-different-neural-network-architectures-39c75a0f03e3) to learn how to classify handwritten digits with varying model depth and width.

### Action Item:
1. Succinctly list the differences between a Convolutional Neural Network and a Fully Connected Neural Network. Discuss layers and their role, and applications of each of the two types of architectures
2. Follow [this guide](https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/) to develop a CNN for [classifying MNIST datasets](http://yann.lecun.com/exdb/mnist/). Evaluate the performance of the final model, and use it to make predictions on new
images.

### Reflection: [ADD]

# WEEK 3 | FUNCTIONS AND PREDICTIONS
## Day 14 | Loss Functions | **[TOC](#table-of-contents)**<br>
### 7/19/2021

### Lesson Plan: 
How to check if a CNN is generating false predictions (i.e. predicting a ‘cat’ image as a ‘dog’) during training? It is typically done using loss functions (also used interchangeably with the term objective functions or cost functions). A loss function is "a function for penalizing the errors in prediction" (Hastie et al.'s "Elements of Statistical Learning", by p.37)

1. For different target tasks, we set different loss functions. Read sections 1 through section 2.1 (through Binary Cross-Entropy) in [this article](https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/).
2. Video lecture: check out this [lecture video](https://www.youtube.com/watch?v=h7iBpEHGVNc) (or [slides](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture3.pdf)) from Dr. Justin Johnson.

### Action Item: 
1. Predict house prices using a simple feed-forward neural network model using [this dataset](https://drive.google.com/file/d/1GfvKA0qznNVknghV4botnNxyH-KvODOC/view). Check out this [article](https://hackernoon.com/build-your-first-neural-network-to-predict-house-prices-with-keras-3fb0839680f4) for a tutorial. Notice the function, which halts the training process when the model stops improving its accuracy and restores the best weights after stopping the training. 
2. Add your code to a new project-page. Also upload the graph showing the mean squared error loss over the training epochs for training and testing sets.

### Reflection: [ADD]

## Day 15 | Activation Functions | **[TOC](#table-of-contents)**<br>
### 7/20/2021

### Lesson Plan: 
One of the key factors in learning good features from images is to introduce nonlinearity through activation functions. An activation function in a neural network defines how the weighted sum of the input is transformed into an output from nodes in a layer of the network. 

1. Check out [this tutorial](https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/) on how to choose activation functions for deep learning. Try out the worked examples to see how different activation functions work.
2. Learn how to implement the [Rectified Linear Unit](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/) (ReLU) (Jump to Section 3 - How to Implement the Rectified Linear Activation Function).

<p align="center">
  How to Choose an Activation Function for a Hidden Layer
</p>

<p align="center">
  <img width="500" src="https://user-images.githubusercontent.com/87036439/127768303-ac239293-203b-4077-b14e-6bded58664bf.jpg" alt="How-to-Choose-an-Hidden-Layer-Activation-Function">
</p>

<p align="center">
  How to Choose an Activation Function for Output Layer
</p>

<p align="center">
  <img width="500" src="https://user-images.githubusercontent.com/87036439/127768307-3e3c59ad-62be-463a-b739-4d4f6be2e1db.png" alt="inbox_6454946_a06a661c6e1e0cc06df1e173e499c505_Traditional Programming (1)">
</p>

<p align="center">
  Possible Activation Functions and Their Graphical Representations
</p>

<p align="center">
  <img width="800" src="https://user-images.githubusercontent.com/87036439/127768036-bb05d864-9b30-4c69-9133-60a71f98459b.gif" alt="EarlyPettyJackrabbit-size_restricted">
</p>!

## Day 16 | Ethics-Driven Machine Learning Practive | **[TOC](#table-of-contents)**<br>
### 7/21/2021

### Lesson Plan:
Improve your understanding of the importance of ethics in the real-world context of AI and automation with this [review](https://hub.packtpub.com/machine-learning-ethics-what-you-need-to-know-and-what-you-can-do/) on machine learning ethics.

### Action Item: 
Build a gender classification model from either of these two datasets: [facial images](https://www.kaggle.com/thanaphatj/gender-classification-of-facial-images-cnn/#data) & [voice](https://www.kaggle.com/primaryobjects/voicegender). Use this [Kaggle notebook](https://www.kaggle.com/thanaphatj/gender-classification-of-facial-images-cnn) as a guide as you develop your own model. Make predictions throughout the process on how accurate the algorithm will be about gender (or age, ethnicity, and gender for the facial dataset). The results may surprise you!

### Reflection: [ADD]

## Day 17 | Image Classification & Machine Learning | **[TOC](#table-of-contents)**<br>
### 7/22/2021

### Lesson Plan:
1. Review some of the basics of image classification techniques with ML, using [this notebook](https://iq.opengenus.org/basics-of-machine-learning-image-classification-techniques/).
2. Review how to build an image classification model using [this walkthrough](https://www.analyticsvidhya.com/blog/2019/01/build-image-classification-model-10-minutes/).

### Action Item:
Examine this [Keras Notebook Activity](https://keras.io/examples/vision/image_classification_from_scratch/) to learn how to build an Image Classification model. Now build your own classification model using this as a guide. Try to modify training data, epochs and layer types and its depth or width, and see how the performance metrics change.

### Reflection: [ADD]

## Day 18 | Data Overfitting & Regularization | **[TOC](#table-of-contents)**<br>
### 7/23/2021

### Lesson Plan:
How to check if your deep learning model is generalizable to new data? A model that learns the training dataset too well, i.e., performing near-perfectly on the training dataset but not performing well on a held-out sample set is called an overfit model, and regularization techniques (like weight decay) are needed to keep overfitting in check.

1. Read about [how to avoid overfitting in deep learning neural networks](https://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/).
2. Study the second half of [this article](https://hackernoon.com/build-your-first-neural-network-to-predict-house-prices-with-keras-3fb0839680f4) starting with the ‘Visualizing Loss and Accuracy’ section). It discusses overfitting and regularization approaches.

### Action Item:
1. [Hands on Tutorial](https://towardsdatascience.com/handling-overfitting-in-deep-learning-models-c760ee047c6e#:~:text=Overfitting%20occurs%20when%20you%20achieve,are%20irrelevant%20in%20other%20data.&text=The%20best%20option%20is%20to%20get%20more%20training%20data): Follow this tutorial about different approaches for handling overfitting in deep learning models using the Twitter US Airline Sentiment data set. 
2. Also, add your observations while changing the loss to regression based functions from the housing prices model.

### Reflection: [ADD]

### Supplemental Activity:
In your housing prices project from earlier, change the loss to a regression based function (e.g. mean squared error or mean absolute error) and see what happens. Review the [Keras API for various loss functions](https://keras.io/api/losses/regression_losses/#meansquarederror-class).

### Ethical Reflection:
In [this article](https://towardsdatascience.com/ethics-in-machine-learning-9fa5b1aadc12), author A. Venkateswaran writes that overfitting deep learning models can be “detrimental to society”. Can you think of one way that an overfit model can be detrimental?

### Reflection: [ADD]

# WEEK 4 | APPLICATIONS OF MACHINE LEARNING
## Day 21 | Upsampling & Autoencoding | **[TOC](#table-of-contents)**<br>
### 7/26/2021

### Lesson Plan: 
So far we have only learned about reducing the size of the input image to a set of numbers or features (i.e. downsampling), but can we get the input image back from these downsampled numbers (i.e. upsampling)? A good place to start while learning about upsampling is with autoencoders, where an encoder module downsamples an input image to a set of numbers or features and a decoder module tries to reconstruct the input image back by upsampling these features.

1. Check out [this upsampling tutorial](https://machinelearningmastery.com/upsampling-and-transpose-convolution-layers-for-generative-adversarial-networks/) about adding upscaling layers to a deep learning model.
2. Follow this [Autoencoder tutorial](https://blog.keras.io/building-autoencoders-in-keras.html) with actual code and visualization to develop autoencoder based reconstruction and noise removal.

### Action Item:
Commit your code to a new project-page from both the interactive tutorials on Github.

### Reflection: [ADD]

## Day 22 | Affective Computing | **[TOC](#table-of-contents)**<br>
### 7/27/2021

### Lesson Plan:
Now that we know how machines perceive and make sense of the world, let’s dive into how machines make sense of humans, specifically, human emotions. Affective Computing is the study and development of systems and devices that can recognize, interpret, process, and simulate human emotions. In this module, we explore the applications of Affective Computing.

1. Watch this [TED Talk](https://www.youtube.com/watch?v=ujxriwApPP4) by Professor Rosalid Picard to learn about the origins of Affective Computing. 
2. [Read about the EMPath 2020 makeathon](https://mysurestart.com/case-study).
3. Check out this [Speech Emotion Analyzer](https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer) project. Download the [h5 model file](https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/saved_models/Emotion_Voice_Detection_Model.h5).
Record your own voice and try it out. (Look at this [AudioRecorder.ipynb](https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/AudioRecorder.ipynb) notebook to learn how to record your voice. For loading and using the .h5 model, examine [this notebook](https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb)). Try changing voices and check your model performance.

### Action Item: 
Commit your code related to the speech emotion model exploration to a new project-page.  In the README, appropriately credit the author of the model. Additionally, comment on how the model was performing, and possible applications of Affective Computing.

### Reflection: [ADD]

## Day 23 | Natural Language Processing | **[TOC](#table-of-contents)**<br>
### 7/28/2021

### Lesson Plan:
Check out this [beginner friendly guide](https://medium.com/@calebkaiser/a-list-of-beginner-friendly-nlp-projects-using-pre-trained-models-dc4768b4bec0) for more applied NLP projects. Make your own variation of one of the six examples that you found most interesting.

### Cheat Sheet: 
Use [this guide](https://towardsdatascience.com/how-to-get-started-in-nlp-6a62aa4eaeff) for accessing various NLP resources.

### Action Item:
1. Build your own movie review classifier using this tutorial: [Sentiment Analysis Task on Movie Reviews](https://www.tensorflow.org/tutorials/keras/text_classification).
2. Commit your code for the NLP model that you tried out to a new projectpage. Comment on your particular variation in your README.
3. Write a reflection piece on the ethical implications of big NLP models such as
GPT-2 and add it to your Responses section

### Reflection: [ADD]

### Supplemental:
Try out this fun [Text Sentiment Analysis Project](https://www.kaggle.com/sanikamal/text-classification-with-python-and-keras).

## Day 24 | Computer Vision (CV) | **[TOC](#table-of-contents)**<br>
### 7/29/2021

### Lesson Plan:
1. Watch this [TED Talk by Rana El Kaliouby - This App Knows How I Feel](https://www.ted.com/talks/rana_el_kaliouby_this_app_knows_how_you_feel_from_the_look_on_your_face/reading-list?language=en).
2. Implement the emotion detection project outlined in this tutorial using OpenCV.

### Supplemental:
Check out this video tutorial on other applications of [Computer Vision](https://cbmm.mit.edu/video/tutorial-computer-vision-4817).

### Action Item:
Commit your code for the emotion detection project to a new projectpage. Try it out on your own face (if possible). Add a screenshot or video snippet of the results. 

## Day 25 | Getting Ready for the Create-A-Thon | **[TOC](#table-of-contents)**<br>
### 7/30/2021

### Reflection: [ADD]

# Index 
## A. Cheat Sheets | **[TOC](#table-of-contents)**<br>
1. [Loss Functions](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html)
2. [Activation Functions](https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html)
3. [Natural Language Processing](https://towardsdatascience.com/how-to-get-started-in-nlp-6a62aa4eaeff)
4. [Convolutional Neural Networks](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks)
5. [Pandas](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)

## B. Libraries | **[TOC](#table-of-contents)**<br>
1. [Scikit-Learn](https://scikit-learn.org/stable/) 
2. [TensorFlow](https://www.datacamp.com/community/tutorials/tensorflow-tutorial) 
3. [Keras](https://www.datacamp.com/community/tutorials/deep-learning-python?utm_source=adwords_ppc&utm_campaignid=1658343521&utm_adgroupid=63833880615&utm_device=c&utm_keyword=keras&utm_matchtype=p&utm_network=g&utm_adpostion=&utm_creative=319519154328&utm_targetid=aud-299261629654:kwd-295071417107&utm_loc_interest_ms=&utm_loc_physical_ms=9016565&gclid=CjwKCAiAxp-ABhALEiwAXm6IyQJo6LA_Z4HlQUiBhrfFwOFL3Vu0bDTjMI53og6hcZfeWIkzEZRBTxoCzbkQAvD_BwE)

## C. Articles | **[TOC](#table-of-contents)**<br>
1. [Python Like You Mean It](https://www.pythonlikeyoumeanit.com/)
2. [Beginner's Guide to Kaggle](https://elitedatascience.com/beginner-kaggle)
3. [10 Tips to Get Started with Kaggle](https://medium.com/@ODSC/10-tips-to-get-started-with-kaggle-fc7cb9316d27)
4. [GitHub README Documentation Formatting](https://guides.github.com/features/wikis/#Formatting-a-readmeE%E2%80%9D)
5. [Scikit-Learn Model Development Activity](https://towardsdatascience.com/an-introduction-to-scikit-learn-the-gold-standard-of-python-machine-learning-e2b9238a98ab)
6. [The Difference Between AI, Machine Learning & Deep Learning](https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/)
7. [Ethics is Machine Learning](https://towardsdatascience.com/ethics-in-machine-learning-9fa5b1aadc12)
8. [A Guide to Deep Learning & Neural Networks](https://serokell.io/blog/deep-learning-and-neural-network-guide)
9. [Confusion Matrices in Machine Learning](https://machinelearningmastery.com/confusion-matrix-machine-learning/)
10. [The Logic of Convolutional Operation in CNNs](https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/)
11. [Algorithmic Bias: Gender Shades](http://gendershades.org/overview.html)
12. [CNNs, Explained](https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939)
13. [How To Choose Loss Functions in Neural Network Training](https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/)
14. [Predict Housing Prices with Keras](https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/)
15. [How To Choose Activations for Deep Learning](https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/)
16. [A Gentle Introduction to the Rectified Linear Unit (ReLU)](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/)
17. [Machine Learning Ethics: What to Know, What to Do](https://hub.packtpub.com/machine-learning-ethics-what-you-need-to-know-and-what-you-can-do/)
18. [Image Classification Model](https://www.analyticsvidhya.com/blog/2019/01/build-image-classification-model-10-minutes/)
19. [How to Avoid Overfitting in Neural Networks](https://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/)
20. [Overfitting & Regularization Approaches](https://hackernoon.com/build-your-first-neural-network-to-predict-house-prices-with-keras-3fb0839680f4)
21. [Keras API for Various Loss Functions](https://keras.io/api/losses/regression_losses/#meansquarederror-class)
22. [EMPath at Affectiva: A Case Study](https://mysurestart.com/case-study)
23. [Beginner-Friendly NLP Projects with Pre-Trained Models](https://medium.com/@calebkaiser/a-list-of-beginner-friendly-nlp-projects-using-pre-trained-models-dc4768b4bec0)
24. [What is the Internet of Things](https://www.wired.co.uk/article/internet-of-things-what-is-explained-iot)

## D. Videos | **[TOC](#table-of-contents)**<br>
1. [Why Should I Care About DEI](https://www.youtube.com/watch?v=yqIpPwkpXXc)
2. [Loss Functions & Optimization](https://www.youtube.com/watch?v=h7iBpEHGVNcrl)
3. [TED: Technology & Emotions](https://www.youtube.com/watch?v=ujxriwApPP4)
4. [TED: This App Knows How I Feel](https://www.ted.com/talks/rana_el_kaliouby_this_app_knows_how_you_feel_from_the_look_on_your_face/reading-list?language=en)
5. [Tutorial: Computer Vision](https://cbmm.mit.edu/video/tutorial-computer-vision-4817)
