{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day 23_Natural Language Processing_Movie Review",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIeRtq-7f6tR"
      },
      "source": [
        "# Importing libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ygf1V5Eeggs8",
        "outputId": "f7466dc4-cf4c-42d9-d84c-ef13310c59d9"
      },
      "source": [
        "# Download the movie review dataset and store it in keras's cache memory\n",
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url,\n",
        "                                    untar=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "print(dataset)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./aclImdb_v1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaoQNJntidgb",
        "outputId": "0ffef22e-a693-4eb0-aff9-436f6b0c1abd"
      },
      "source": [
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "print(dataset_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./aclImdb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvrT6j-8i0U8",
        "outputId": "a5f9a7bf-e853-495b-c22d-fd4cbf75f97f"
      },
      "source": [
        "#Print the contents of the \"aclImdb\" directory\n",
        "os.listdir(dataset_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['imdb.vocab', 'imdbEr.txt', 'train', 'test', 'README']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dogHDN1LjJSy",
        "outputId": "00cc1334-0786-4494-d1a0-8bb912966d03"
      },
      "source": [
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "os.listdir(train_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['unsupBow.feat',\n",
              " 'urls_pos.txt',\n",
              " 'neg',\n",
              " 'labeledBow.feat',\n",
              " 'urls_unsup.txt',\n",
              " 'urls_neg.txt',\n",
              " 'pos',\n",
              " 'unsup']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPZ9Eg2VjmIh",
        "outputId": "639f397a-7a52-4d1d-ecc1-469a0c149a3a"
      },
      "source": [
        "# Randomly select a file inside \"pos\" directory and print its content\n",
        "\n",
        "sample_file = os.path.join(train_dir, 'pos/1181_9.txt')\n",
        "with open(sample_file) as f:\n",
        "  print(f.read())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rachel Griffiths writes and directs this award winning short film. A heartwarming story about coping with grief and cherishing the memory of those we've loved and lost. Although, only 15 minutes long, Griffiths manages to capture so much emotion and truth onto film in the short space of time. Bud Tingwell gives a touching performance as Will, a widower struggling to cope with his wife's death. Will is confronted by the harsh reality of loneliness and helplessness as he proceeds to take care of Ruth's pet cow, Tulip. The film displays the grief and responsibility one feels for those they have loved and lost. Good cinematography, great direction, and superbly acted. It will bring tears to all those who have lost a loved one, and survived.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAipJZbzkYW3"
      },
      "source": [
        "#Directory tree is expected by this function \"text_dataset_from_directory\"\n",
        "\"\"\"\n",
        "main_directory/\n",
        "...class_a/\n",
        "......a_text_1.txt\n",
        "......a_text_2.txt\n",
        "...class_b/\n",
        "......b_text_1.txt\n",
        "......b_text_2.txt\n",
        "\"\"\"\n",
        "#Remove the \"unsup\" directory tree (itself and its subdirectories and files)\n",
        "remove_dir = os.path.join(train_dir, 'unsup') #create a path to the directory \n",
        "shutil.rmtree(remove_dir) #remove the unsup directory\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K-Qpui0lwdT",
        "outputId": "3f5050fe-7c2a-4058-b5a5-4effc728f87c"
      },
      "source": [
        "batch_size = 32\n",
        "seed = 42\n",
        "\n",
        "#copy 80% of training data to \"raw_train_ds\" (training_split)\n",
        "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size = batch_size,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'training', seed = seed)\n",
        "print(len(raw_train_ds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeEjrhEmm162",
        "outputId": "79f7e462-6a70-43e8-a166-8e1658bb856b"
      },
      "source": [
        "#Take the first batch out of the 625 batches (625*32 batch_size = 20,000 training examples)\n",
        "#Print all 32 examples in each batch\n",
        "\n",
        "for text_batch, label_batch in raw_train_ds.take(1): \n",
        "  for i in range(32):\n",
        "    print(\"Review\", text_batch.numpy()[i])\n",
        "    print(\"Label\", label_batch.numpy()[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review b'\"Pandemonium\" is a horror movie spoof that comes off more stupid than funny. Believe me when I tell you, I love comedies. Especially comedy spoofs. \"Airplane\", \"The Naked Gun\" trilogy, \"Blazing Saddles\", \"High Anxiety\", and \"Spaceballs\" are some of my favorite comedies that spoof a particular genre. \"Pandemonium\" is not up there with those films. Most of the scenes in this movie had me sitting there in stunned silence because the movie wasn\\'t all that funny. There are a few laughs in the film, but when you watch a comedy, you expect to laugh a lot more than a few times and that\\'s all this film has going for it. Geez, \"Scream\" had more laughs than this film and that was more of a horror film. How bizarre is that?<br /><br />*1/2 (out of four)'\n",
            "Label 0\n",
            "Review b\"David Mamet is a very interesting and a very un-equal director. His first movie 'House of Games' was the one I liked best, and it set a series of films with characters whose perspective of life changes as they get into complicated situations, and so does the perspective of the viewer.<br /><br />So is 'Homicide' which from the title tries to set the mind of the viewer to the usual crime drama. The principal characters are two cops, one Jewish and one Irish who deal with a racially charged area. The murder of an old Jewish shop owner who proves to be an ancient veteran of the Israeli Independence war triggers the Jewish identity in the mind and heart of the Jewish detective.<br /><br />This is were the flaws of the film are the more obvious. The process of awakening is theatrical and hard to believe, the group of Jewish militants is operatic, and the way the detective eventually walks to the final violent confrontation is pathetic. The end of the film itself is Mamet-like smart, but disappoints from a human emotional perspective.<br /><br />Joe Mantegna and William Macy give strong performances, but the flaws of the story are too evident to be easily compensated.\"\n",
            "Label 0\n",
            "Review b'Great documentary about the lives of NY firefighters during the worst terrorist attack of all time.. That reason alone is why this should be a must see collectors item.. What shocked me was not only the attacks, but the\"High Fat Diet\" and physical appearance of some of these firefighters. I think a lot of Doctors would agree with me that,in the physical shape they were in, some of these firefighters would NOT of made it to the 79th floor carrying over 60 lbs of gear. Having said that i now have a greater respect for firefighters and i realize becoming a firefighter is a life altering job. The French have a history of making great documentary\\'s and that is what this is, a Great Documentary.....'\n",
            "Label 1\n",
            "Review b\"It's boggles the mind how this movie was nominated for seven Oscars and won one. Not because it's abysmal or because given the collective credentials of the creative team behind it really ought to deserve them but because in every category it was nominated Prizzi's Honor disappoints. Some would argue that old Hollywood pioneer John Huston had lost it by this point in his career but I don't buy it. Only the previous year he signed the superb UNDER THE VOLCANO, a dark character study set in Mexico, that ranks among the finest he ever did. Prizzi's Honor on the other hand, a film loaded with star power, good intentions and a decent script, proves to be a major letdown.<br /><br />The overall tone and plot of a gangster falling in love with a female hit-man prefigures the quirky crimedies that caught Hollywood by storm in the early 90's but the script is too convoluted for its own sake, the motivations are off and on the whole the story seems unsure of what exactly it's trying to be: a romantic comedy, a crime drama, a gangster saga etc. Jack Nicholson (doing a Brooklyn accent that works perfectly for De Niro but sounds unconvincing coming from Jack) and Kathleen Turner in the leading roles seem to be in paycheck mode, just going through the motions almost sleepwalking their way through some parts. Anjelica Huston on the other hand fares better but her performance is sabotaged by her character's motivations: she starts out the victim of her bigot father's disdain, she proves to be supportive to her ex-husband, then becomes a vindictive bitch that wants his head on a plate.<br /><br />The colours of the movie have a washed-up quality like it was made in the early 70's and Huston's direction is as uninteresting as everything else. There's promise behind the story and perhaps in the hands of a director hungry to be recognized it could've been morphed to something better but what's left looks like a film nobody was really interested in making.\"\n",
            "Label 0\n",
            "Review b'The concept of the legal gray area in Love Crimes contributes to about 10% of the movie\\'s appeal; the other 90% can be attributed to it\\'s flagrant bad-ness. To say that Sean Young\\'s performance as a so-called district attorney is wooden is a gross understatement. With her bland suits and superfluous hair gel, Young does a decent job at convincing the audience of her devout hatred for men. Why else would she ask her only friend to pose as a prostitute just so she can arrest cops who try to pick up on them? This hatred is also the only reason why she relentlessly pursues a perverted photographer who gives women a consensual thrill and the driving force behind this crappy movie. Watching Young go from frigid to full-frontal nudity does little to raise interest, but the temper tantrum she throws standing next to a fire by a lake does. Watching her rant and rave about her self-loathing and sexual frustration makes Love Crimes worth the rental fee, but it\\'s all downhill to and from there. Despite her urge to bring Patrick Bergin\\'s character to justice, her policing skills completely escape her in the throes of her own tired lust and passion. Patrick Bergin does a decent enough job as a slimy sociopath; if it worked in Sleeping With the Enemy it sure as hell can work in this. But I can\\'t help but wonder if the noticeable lack of energy Young brings to the film conflicts with his sliminess. I\\'m guessing it does and the result is a \"thriller\" with thrills that are thoroughly bad and yet comedic.'\n",
            "Label 0\n",
            "Review b\"This flick reminds me some really bad science-fiction movies from 50's and 60's.It is not scary or interesting,but it's dull,cheesy and stupid.Special effects are laughable,all actors are ludicrous and the ending is simply awful.Don't waste your money,rent or buy something better.I give it 3.5 out of 10( I found this turkey quite amusing because of its stupidity).\"\n",
            "Label 0\n",
            "Review b'Finally a thriller which omits the car chases, explosions and other eye catching effects. The movie combines a simple plot (assasination of a french president) with an excellent background. It takes a look behind mans behavior with authorities, and explains why we would obey almost every order (even murder) which would be given to us.<br /><br />Furthermore it shows us how secret services can manipulate the run of history and how hardly they can be controlled. The best thing on this movie is, that there is no classic \"Hollywood end\" which can easily be predicted.'\n",
            "Label 1\n",
            "Review b\"I'm a Christian who generally believes in the theology taught in Left Behind. That being said, I think Left Behind is one of the worst films I've seen in some time.<br /><br />To have a good movie, you need to have a well-written screenplay. Left Behind fell woefully short on this. For one thing, it radically deviates from the book. Sometimes this is done to condense a 400-page novel down to a two-hour film, but in this film I saw changes that made no sense whatsoever.<br /><br />Another thing, there is zero character development. When characters in the story get saved (I won't say who), the book makes it clear that it's a long, soul-searching process. In the film it's quick and artificial. The book is written decently enough where people like Rayford Steele, Buck Williams and Hattie Durham seem real, but in the movie scenarios are consistently given the quick treatment without anything substantial. In another scene where one character gets angry about being left behind (again, I won't say who), it seems artificial.<br /><br />I realize as a Christian it's unedifying for me to say I disliked this film, but I can't in a good conscience recommend a film that I feel was horribly done. Perhaps it would've been better to make the first book into 2-3 films. Either way, Christians need to realize that to be taken seriously as filmmakers, we need to start by putting together a film in a quality way. I realize a lot of effort probably went into Left Behind, but that's the way I see it.\"\n",
            "Label 0\n",
            "Review b'This effort is based on the true story of Jim Morris, a high school science teacher/baseball coach, who is inspired by his players to try out for the pros and fulfill his life-long dream of playing in the majors. Dennis Quaid, no stranger to sports films, plays Morris with enough conviction to make the part work and the producers do a credible job of recreating the real-world events that led to Morris brief stint as a relief pitcher for the woefull Tampa Bay Devil Rays. The first half of the film, dealing with his rag tag bunch of High School Baseball players (all of whom look way too old to actualy be in High School) is less effective and probably a bit too long. Overall the film does suffer from some pacing issues and a few extra subplots that we probably could have done without. However, it is still a fairly involving movie with an inspirational theme that proves once again that baseball is the national pastime for a reason. GRADE: B-'\n",
            "Label 1\n",
            "Review b\"Live Feed is set in some unnamed Chinese/Japanese Asian district somewhere as five American friends, Sarah (Ashley Schappert), Emily (Taayla Markell), Linda (Caroline Chojnacki), Mike (Lee Tichon) & Darren (Rob Scattergood) are enjoying a night on the town & taking in the sights. After a scuffle in a bar with a Japanese Triad boss (Stephen Chang) they decide to check out a porno theatre, as you would. Inside they are separated & quickly find out that the place belongs to the Triad boss who uses it to torture & kill people for reasons which aren't made clear. Can local boy Miles (Kevan Ohtsji) save them?<br /><br />This Canadian production was co-written, produced & directed by Ryan Nicholson who also gets a prosthetic effects designer credit as well, one has to say that Live Feed is another pretty poor low budget shot on a camcorder type horror film that seems to exist only to cash in on the notoriety & success of Hostel (2005) & the mini craze for 'torture porn' as it's become known. According the IMDb's 'Trivia' section for Live Feed writer & director Nicholson wrote it after hearing about certain activities taking place in live sex theatres, for my money I reckon he wrote it after watching Hostel! The script is pretty poor, there is no basic reason given as to why this porno theatre has a big fat ugly freak dressed in bondage gear lurking around torturing & killing people, none. Was it for the Triads? Was it for his pleasure? Was it to make snuff films to sell? Some sort of explanation would have been nice. Also why did he turn on the Triad boss at the end? If your looking for a film with a coherent story then forget about Live Feed. It seemed to me to be some sort of uneasy misjudged mix of sex, S&M, horror, torture, gore & action films which doesn't come off. I mean just setting a horror film in a porn theatre isn't automatically going to make your film any good, there still needs to be a decent script & story, right? The character's were fairly poor clich\\xc3\\xa9s & some of their actions & motivations were more than a little bit questionable. It moves along at a reasonable pace, it's fairly sleazy mixing gore, sex & nudity but it does look cheap which lessens the effect.<br /><br />Director Nicholson doesn't do anything special here, the editing is choppy & annoying, he seems to think lighting almost every scene with neon lights is a good idea & the film has a cheap look about it. Available in both 'R' & 'Unrated' versions I saw the shorter cut 'R' version which really isn't that gory but I am prepared to give the benefit of the doubt to the 'Unrated' version & say that it might be much, much gorier but I can't say for sure. There's a fair amount of nudity too if that's your thing. I wouldn't say there's much of an atmosphere or many scares here because there isn't & aren't respectively although it does have a sleazy tone in general which is something it has going for it I suppose.<br /><br />Technically Live Feed isn't terribly impressive, the blood looks a little too watery for my liking & entire scenes bathed in annoying neon lights sometimes makes it hard to tell whats happening, it to often looks like it was shot on a hand-held camcorder & the choppy editing at least on the 'R' rated version is at times an annoying mess. Shot on location in an actual porn theatre somewhere in Vancouver in Canada. The acting is poor, sometimes I couldn't tell if the actresses in this were supposed to be crying or laughing...<br /><br />Live Feed is not a film I would recommend anyone to rush out & buy or rent, I didn't think much of it with it's very weak predictable storyline lacking exposition & which goes nowhere, poor acting & less than impressive gore (at least in the 'R' rated cut anyway). Watch either Hostel films again or instead as they are superior.\"\n",
            "Label 0\n",
            "Review b\"It starts slowly, showing the dreary lives of the two housewives who decide to rent a castle in Italy for the month of April, but don't give up on it. Nothing much happens, but the time passes exquisitely, and there are numerous sly jokes (my favorite is the carriage ride in the storm, which I find hilarious). The movie is wonderfully romantic in many senses of the word, the scenery is beautiful (as is Polly Walker), and the resolutions in the movie are very satisfying.<br /><br />The movie takes a couple of liberties with the book, the biggest being with the Arbuthnot/Briggs/Dester business, but I actually preferred the movie's version of this (it may be more sentimental, but I felt that it was more consistent with the tone of the story, and anyway I like sentiment when it's well done).<br /><br />An excellent movie, especially as a date movie during lousy weather.\"\n",
            "Label 1\n",
            "Review b\"An uninteresting addition to the stalk 'n slash cycle which dominated the horror genre in the 1980's. This was filmed as Pranks but released as The Dorm That Dripped Blood which is an obvious steal from the 1970 horror anthology The House That Dripped Blood. Daphne Zuniga is the only recognisable face in the cast and this was her first horror movie (she has also appeared in The Initiation and The Fly II).\"\n",
            "Label 0\n",
            "Review b'There is so much that is wrong with this film, but to sum it up: Terrible acting- so bad it must have been on purpose. poor script - they may have had some good ideas but this was not the best way to present the story. ridiculously bad ending- in some cases the ending manages to save the film-not in this case. if you manage to sit through the entire film you will want to kick yourself at the end because the ending is not even worth waiting for. This is the worst film i have seen in a long time. It was complete torture sitting through this film, i would have appreciated someone warning me in advance. So do yourself a favor. Watch this film only if you have absolutely nothing better to do. Even then you will regret having put yourself through the unspeakable torture.'\n",
            "Label 0\n",
            "Review b\"I agree with the above comment, I love the realism in this, and in many movies (not just movies on eating disorders) the producers seem to forget that. They take an every day problem and create a hugely dramatic scene and then come the end of the movie everything is perfect again, which I dislike because its not reality. Not meaning to say things can't get better, and not meaning to say things don't in this movie, but it doesn't spend most of the movie creating all these problems, and come the end of the movie everything is perfect again. When people have eating disorders people don't just admit it and want to get better, and then life is peachy, it takes time, and I like how in this movie we grow with the characters, we go through the difficulties with them, getting better and worse, because it is a very important part of the movie. It gets into the minds of people with eating disorders, and shows the complications and pain, in a very realistic way, and I loved that. I also love how it shows The secrecy and betrayal people feel when suffering from eating disorders, it is scary to see how people react when they find out, especially if they approve of it. I thought this movie was very touching and beautiful and well told, and defiantly one of my favourites.\"\n",
            "Label 1\n",
            "Review b\"I came here for a review last night before deciding which TV movie to settle in front of, and those I found made this one look unmissable. How misled I feel!<br /><br />Firstly, it needs to be pointed out up front that this is very much a housewife's daytime movie. The performances are wooden, every sentence is an attempt at 'poignant' in the way that housewife's daytime movies and bad soap operas always are, and it is based in that predictable and well-trodden premise that men (particularly soldiers) are essentially violent and incompassionate. The whole movie is about the 'drama' apparent in the moments when the male characters threaten to develop a second dimension.<br /><br />If that sounds tolerable (or even enjoyable) to you, then be warned. Linda Hamilton's German accent, while quite good, is painfully distracting - as is her face, for some reason. The other performances are no doubt an enduring source of embarrassment to their perpetrators, with painfully thin and obvious characterizations being the order of the day. There are few surprises, but do watch for the 'Monty Pythonesque' endless supply of food and drink that miraculously appears from the hungry soldiers' knapsacks!<br /><br />I wasn't expecting action, but I had hoped for beautiful or textural or emotionally charged. What I got was a particularly bad Christmas 'feelgood' story that will have an intelligent audience cringing with the crapulence of it all.<br /><br />Watch it under the folowing circumstances: 1: There's nothing else on. 2: You are a fan of predictable 'housewife takes on men and wins' TV movies. 3: The only way you can appreciate a true story is when Hollywood turns it into a feature film. 4: You've imbibed enough nog that your emotions are easily stirred by unsophisticated storytelling.\"\n",
            "Label 0\n",
            "Review b\"At first, I thought the Ring would be a more than normal movie with it's ordinary plot. How surprised was I! Of course, the plot is simple - one girl is in love with two men - but Hitchcock brings it to us on a silver platter, with laughter and fear, with compassion and anguish. The way he depicts the popular crowds of the fair, the strength of the attraction of the girl to both men, the tragic elements that come together with techniques that open the mind to most of his greatest movies(North by Northwest, the Rope, etc.). The master did it great even before his thirties!\"\n",
            "Label 1\n",
            "Review b'I know the film snobs are snorting. But if you\\'re looking for a surprisingly fun ride through the B-movie jungle, try \"Jake Speed\".<br /><br />A little thin at times, but its one-liners and the location more then make up for this. John Hurt(God love him), seems to be having fun doing his role as the ultra evil white slaver. The nemesis of Crawfords, Jake Speed. He adds a dimension to the film that only a pro like Hurt could provide. Crawford and Dennis Christopher( Jakes sidekick) are a good team,although you do wonder why they both put up with each other.However ,together both Crawford and Christopher portray a team that is just so much fun that, if you can get over yourself for a moment, you may find yourself acting like a kid again at the situations and the inherent suspense they provide.The delicious Karen Kopins does a great job as the damsel in distress that is more concerned about the motives of her rescuer then her tormentor.<br /><br />I have yet to find a movie that is as much fun without getting preachy,or bogging down the movie by trying too hard. Not every movie has to be the latest \"Citizen Kane\". And trust me,Wells was an original. So lets remember that sometimes, movies are for fun.Not social commentary or attempting to sway an audience politically. But just for the sheer fun of being alive and living in a time when our hero\\'s live in a celluloid dimension.'\n",
            "Label 1\n",
            "Review b\"Ahista Ahista is one little small brilliant. I started watching it, and at the beginning I got a little bored since the pacing was slow and the main idea of one guy meeting a girl who is lost was not really new. But as the film went on, I started getting increasingly and gradually engaged by the film, the fantastic writing and the charming romance. The film was extremely simple and natural and after some time I felt I was watching a real documentation of one guy's life. There's one very good reason the film got this feel, and it's the fresh talent called Abhay Deol. He is extremely convincing as the simple, kind-hearted and struggling Ankush, whose new love motivates him to make amends and fight for a better life. Throughout the film, he is presented as an ordinary mischievous prankster, but also as a helping and loving person, who, like anyone else will do anything to protect his love. Deol portrays all the different shades of his character, whether positive or negative, naturally and with complete ease.<br /><br />Shivam Nair's direction is very good. His depiction of the life of people in the rural neighbourhood is excellent, but what gets to be even more impressive is his portrayal of Ankush's relationships with the different people who surround him, including his friends and his love interest Megha who he is ready to do anything for. I also immensely liked the way Nair portrayed his interaction with his friend's loud and plump mother whom he calls 'khala' (aunty). He likes to drive her crazy and annoy her on every occasion, yet we see that she occupies a very special place in his heart and is like a mother-figure to him as evidenced in several scenes. Except for Abhay, the rest of the cast performed well. Though Soha Ali Khan did not stand out according to me, she was good and had some of her mother's charm. The actors who played Ankush's friends were very good as was the actress who played Ankush's 'khala'.<br /><br />Apart from the performances, the film's writing was outstanding. The dialogues were sort of ordinary yet brilliant, and the script was also fantastic. That's mainly because despite a not-so-new story it was never overdone or melodramatic and there were no attempts to make it look larger-than-life. The film's biggest weakness was Himesh Reshammiya's uninspiring music which was unsuitable for this film. Otherwise, Ahista Ahista was a delightful watch and it got only better with every scene. The concept may not be new, but the film manages to look fresh and becomes increasingly heartwarming as the story goes by. The ending was bittersweet, kind of sad yet optimistic. In short, this movie really grows on you slowly, and this can be easily attributed to the wonderful writing, the moving moments, the charming romance, the realistic proceedings, and of course Abhay Deol's memorable performance.\"\n",
            "Label 1\n",
            "Review b\"This is another one of those movies that could have been great. The basic premise is good - immortal cat people who kill to live, etc. - sort of a variation on the vampire concept.<br /><br />The thing that makes it all fall apart is the total recklessness of the main characters. Even sociopaths know that you need to keep a low profile if you want to survive - look how long it took to catch the Unibomber, and that was because a family member figured it out.<br /><br />By contrast, the kid (and to a lesser extent, the mom) behave as though they're untouchable. The kid kills without a thought for not leaving evidence or a trail or a living witness. How these people managed to stay alive and undiscovered for a month is unbelievable, let alone decades or centuries.<br /><br />It's really a shame - this could have been so much more if it had been written plausibly, i.e., giving the main characters the level of common sense they would have needed to get by for so long.<br /><br />Other than that, not a bad showing. I loved the bit at the end where every cat in town converges on the house - every time I put out food on the porch and see our cats suddenly rush in from wherever they were before, I think of that scene.\"\n",
            "Label 0\n",
            "Review b'I was looking through the movie listings in my area on yahoo and seen a movie that had not been advertised. I looked closer and noticed that Peter Falk and Paul Reiser were in it. Having watched \"Mad about you\", once, I was not a fan of Paul Reiser. However, I am a big fan of Peter Falk. So the spouse and I took a chance. We were both swept into this story. The beautiful scenery, the heartfelt acting and the sense of family and moral values that are seldom seen in movies and the world today. Not that sappy emoted junk, but real life situations from real life-like people. I even have to say, Paul Reiser was excellent, although, I still won\\'t watch \"Mad about you\". I don\\'t know where this movie has gone. I heard it was put out in limited release. It should be shared with the world. It is one of the finest movies I have seen. M.'\n",
            "Label 1\n",
            "Review b\"This is one of those cheaply made TV Movies were the characters seem to lose all sense. The premise of the story, the kidnapping of a son by the boy's father,is very good. But the story just seems to beggar belief. Whenever the mother is advised not to do anything you know fine well she is going to do it. It is a bit far fetched and not worthy of a viewing.\"\n",
            "Label 0\n",
            "Review b'Great movie - especially the music - Etta James - \"At Last\". This speaks volumes when you have finally found that special someone.'\n",
            "Label 0\n",
            "Review b\"I am shocked. Shocked and dismayed that the 428 of you IMDB users who voted before me have not given this film a rating of higher than 7. 7?!?? - that's a C!. If I could give FOBH a 20, I'd gladly do it. This film ranks high atop the pantheon of modern comedy, alongside Half Baked and Mallrats, as one of the most hilarious films of all time. If you know _anything_ about rap music - YOU MUST SEE THIS!! If you know nothing about rap music - learn something!, and then see this! Comparisons to 'Spinal Tap' fail to appreciate the inspired genius of this unique film. If you liked Bob Roberts, you'll love this. Watch it and vote it a 10!\"\n",
            "Label 1\n",
            "Review b\"when my sister said this movie was gonna be good i had second thoughts but i watched it and it was actually funny. basically the movie is made of a weird girl who goes to a small town where no one likes her and she just wants to go there and get the reading of her aunts will don so she can go. but its not all that easy. In this movie you will come across hilarious humor, a witch, a book of spells/recopies, a mentally challenged uncle and a dog. You will understand the meaning of the word freak a after anyways i hope you run right out and try to find this really old movie. hope you like it in total i will have to give it a 0.... no I'm totally joking ill give it a 9 hope you understand that you will laugh, you will scream and you may just be offended.<br /><br />love yours truly: Dakota you can email me at dakota_loves_it@hot mail.com if you wanna\"\n",
            "Label 1\n",
            "Review b'From the very opening scene you will notice just how hard they tried to mimic the very smart and powerful \\'Cruel Intentions\\', and how flat it landed. You\\'ll also notice what a terrible choice they made by casting Robin Dunne as Valmont... Then in the second scene, you meet the two best things in this movie, Amy Adams and Mimi Rogers as Kathryn and her mother. That is, if you can get past the fact that Kathryn wasn\\'t blonde in the first film... Then the movie goes on, you see the cheap romantic story from miles ago, and you notice Sebastian has already met an Anette in the past, here called Danielle, and a Cecile, here called Cherie... How original is that for a prequel. Then it turns into a low budget \\'Wild Things\\' type of film with lots and lots of oh-my \"twists\". As I mentioned, Robin Dunne was a very bad choice. Not that he is a bad actor, he\\'s good.. He just doesn\\'t have the charisma Ryan did. Amy Adams, who is in my opinion one of the most talented young actresses of our time, once again delivers. But with all the talent in the world, there is no way one could save this trash. As a whole, this \"movie\" feels like a \\'Beverly Hills, 90210\\' episode. The score has been stolen from \\'Cruel Intentions\\' and \\'Jawbreaker\\'... Yes, they used the score from JAWBREAKER... Couldn\\'t they at least leave that one alone?! You\\'ll want to pass this one. If you want more Cruel Intentions, watch Stephen Frears\\' Dangerous Liaisons.'\n",
            "Label 0\n",
            "Review b\"Being a fan of silent films, I looked forward to seeing this picture for the first time. I was pretty disappointed. <br /><br />As has been mentioned, the film seems to be one long, long, commercial for the Maxwell automobile. <br /><br />Perhaps if the chase scene was about half the length that it is, I may have enjoyed the film more. But it got old very fast. And while I recognize that reality is stretched many times in films, without lessening a viewer's enjoyment, what was with the Mexican bandits? I mean, they are chasing a car through the mountains, a car that most of the time is moving at about one mile per hour, yet they can't catch up to it?\"\n",
            "Label 0\n",
            "Review b'Mr Perlman gives a standout performance (as usual). Sadly, he has to struggle with an underwritten script and some nonsensical set pieces.<br /><br />Larsen is in \"Die Hard\" mode complete with singlet and bulging muscles, I\\'m sure he could do better but seems satisfied to grimace and snarl through his part.<br /><br />The lovely Erika is very decorative (even though fully clothed!) and shows some signs of \"getting\" acting at last.<br /><br />SFX are mainly poor CGI and steals from other movies.<br /><br />The shootouts are pitiful - worthy of the A-Team<br /><br />Not even worth seeing for Perlman - AVOID'\n",
            "Label 0\n",
            "Review b\"A lot of the problem many people have with this movie is that they seem to think that the story should have been more entertaining (ignoring it is based on a true story) or ranting against a film that glorifies Che (which it really doesn't). This film is very close to Jon Anderson's definitive bio on Che and gets the story right. Soderburgh does an excellent job of setting the mood for the unraveling debacle that was Che's Bolivian adventure. You really get the impression of the total timidity and bewilderment of the Bolvian peasant to Che's revolutionary ideas or of the difficulties that his men faced with hunger and the terrain. Sorry to bore the attention challenged movie fan out there but that was how it happened. So don't go into this movie expecting a Rambo shoot em up, its a true story!\"\n",
            "Label 1\n",
            "Review b'<br /><br />Ok, well I rented this movie while I was bed ridden hopped up on pain killers, and let me say, It didn\\'t help the film any.<br /><br />The film is about a man who buys a car as he is going through a midlife crisis, he loves the car more than anything around him, one day his wife decides to borrow the car. Since I don\\'t want to spoil (not that there was anything to spoil) I shall let your imagination figure out the \"Zany\" (and I use that word lightly) antics that follow.<br /><br />I had to fight to stay awake through this snore a minute sleeper of a film, and I would like to say that if you are venturing to the movie store and are thinking about being adventurous, please don\\'t, it\\'s a waste of the film it was printed on.<br /><br />Then again I could be wrong...'\n",
            "Label 0\n",
            "Review b'This picture seemed way to slanted, it\\'s almost as bad as the drum beating of the right wing kooks who say everything is rosy in Iraq. It paints a picture so unredeemable that I can\\'t help but wonder about it\\'s legitimacy and bias. Also it seemed to meander from being about the murderous carnage of our troops to the lack of health care in the states for PTSD. To me the subject matter seemed confused, it only cared about portraying the military in a bad light, as A) an organzation that uses mind control to turn ordinary peace loving civilians into baby killers and B) an organization that once having used and spent the bodies of it\\'s soldiers then discards them to the despotic bureacracy of the V.A. This is a legitimate argument, but felt off topic for me, almost like a movie in and of itself. I felt that \"The War Tapes\" and \"Blood of my Brother\" were much more fair and let the viewer draw some conclusions of their own rather than be beaten over the head with the film makers viewpoint. F-'\n",
            "Label 0\n",
            "Review b\"I have to say I totally loved the movie. It had it's funny moments, some heartwarming parts, just all around good. Me, personally, really liked the movie because it's something that finally i can relate to my childhood. This movie, in my opinion, is geared more towards the young gay population. It shows how a young gay boy would be treated while growing up. All the taunting, name-calling, and not knowing is something I, like most other young feminine boys, will always remember, and now finally a movie that illustrates how hard it really is to grow up gay. So, I would definitely recommend seeing this movie. Probably shouldn't really watch it until a person is old and mature enough to understand it\"\n",
            "Label 1\n",
            "Review b\"Nobody said movies had to be realistic did they? I really liked this movie because I remember when I first saw it in junior high. For all the kids who remember the PMRC and albums before there were warning stickers, it's a cool story for all those kids who were part of the mid to late 80's headbanger crowd.\"\n",
            "Label 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-zhwwYAoiGs",
        "outputId": "4560a098-5224-45a3-f3ed-f89909520ec8"
      },
      "source": [
        "# Print corresponding string names of integer classes\n",
        "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
        "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label 0 corresponds to neg\n",
            "Label 1 corresponds to pos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLj5Pg6Fo2ro",
        "outputId": "3329fb7f-9f8f-4eee-c0ec-adf0ab11310a"
      },
      "source": [
        "#Copy remaining 2-% of training examples to \"raw_val_ds\" (validation split)\n",
        "#Same seed ensures no duplicates in both splits\n",
        "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size = batch_size,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'validation', seed = seed)\n",
        "print(len(raw_train_ds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zoQTKuiydQ4",
        "outputId": "a1190668-30ae-4778-b170-69c09f74a2cf"
      },
      "source": [
        "# Copy remaining 20% of training examples to \"raw_val_ds\" (validation split)\n",
        "# Same seed ensures no duplicates in both splits\n",
        "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train', \n",
        "    batch_size=batch_size, \n",
        "    validation_split=0.2, \n",
        "    subset='validation', \n",
        "    seed=seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxAMgUSTpa_U",
        "outputId": "95cdf5fa-59c1-4d4d-b104-e5ea2bd535b1"
      },
      "source": [
        "#create test split. Cop all the test examples to \"raw_test_ds\" (test split)\n",
        "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/test',\n",
        "    batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vh55qjKp-tK"
      },
      "source": [
        "# Define function for preprocessing text\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  #regex_replace(input, pattern, replace)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  # Replace punctuations with empty string (i.e. remove punctuations)\n",
        "  return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation),\n",
        "                                  '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loCv6SQcrPR7"
      },
      "source": [
        "#Define layer that will perform vectorization\n",
        "max_features = 10000 #take 10,000 unique words for preprocessing. This creates a token dictionary with max words being 10,000\n",
        "sequence_length = 250 #length set for each review\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization, \n",
        "    max_tokens = max_features, \n",
        "    output_mode='int',\n",
        "    output_sequence_length = sequence_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hndgWtfusVBb"
      },
      "source": [
        "#Make a text -only dataset (without lables), then call adapt() (i.e. fit)\n",
        "train_text = raw_train_ds.map(lambda x, y:x)\n",
        "vectorize_layer.adapt(train_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H7YWXzWutIc"
      },
      "source": [
        "def vectorize_text(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer(text), label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vHA6VR6uwjb",
        "outputId": "11d40daa-4ccc-4049-e324-d6095645532d"
      },
      "source": [
        "# retrieve a batch (of 32 reviews and labels) from the dataset\n",
        "# iter() makes it iterable, next() selects batch 0\n",
        "text_batch, label_batch = next(iter(raw_train_ds))\n",
        "#select first review out of 32 reviews in batch 0\n",
        "first_review, first_label = text_batch[0], label_batch[0]\n",
        "print(\"Review\", first_review)\n",
        "print(\"Label\", raw_train_ds.class_names[first_label])\n",
        "print(\"Vectorized review\", vectorize_text(first_review, first_label))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review tf.Tensor(b\"A very well made film set in early '60s communist Yugoslavia. The five young actors who are the teenagers at the center of the story give strong, sincere and emotionally deep performances. A clear depiction of how the natural trust and naivete inherent in teens can be easily manipulated and how that impacted the rest of their lives. Highly recommended.\", shape=(), dtype=string)\n",
            "Label pos\n",
            "Vectorized review (<tf.Tensor: shape=(1, 250), dtype=int64, numpy=\n",
            "array([[   3,   52,   70,   90,   19,  258,    8,  397, 1668, 4948,    1,\n",
            "           2,  692,  184,  153,   34,   23,    2, 2626,   30,    2, 3034,\n",
            "           5,    2,   61,  198,  580, 5859,    4, 1665, 1007,  364,    3,\n",
            "         669, 3025,    5,   87,    2, 1149, 1650,    4,    1, 5985,    8,\n",
            "        2580,   68,   27,  768,    1,    4,   87,   12,    1,    2,  322,\n",
            "           5,   66,  476,  519, 1148,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0]])>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckjjuvDWvli8",
        "outputId": "1dfb4c53-3bd1-41b9-ce17-701d790ecca3"
      },
      "source": [
        "# Print tokens corresponding to indeces\n",
        "print(\"1287 ---> \",vectorize_layer.get_vocabulary()[1287])\n",
        "print(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])\n",
        "print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1287 --->  likely\n",
            " 313 --->  poor\n",
            "Vocabulary size: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZKKg58EvlmA"
      },
      "source": [
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "val_ds = raw_val_ds.map(vectorize_text)\n",
        "test_ds = raw_test_ds.map(vectorize_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3dG8SY9wbCB"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vpub3AVAwiRM"
      },
      "source": [
        "embedding_dim = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVRzKTQdwnvx",
        "outputId": "a4154878-4102-48c9-8091-066038587c54"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Embedding(max_features + 1, embedding_dim),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Dense(1)])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEXhnoUowtZp"
      },
      "source": [
        "# from_logits True implies y_pred are probabilities, anything >0 is predicated as 1\n",
        "model.compile(loss=losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer='adam',\n",
        "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EZnNjDmxF9I",
        "outputId": "78e86cb3-773a-4dfc-c204-a9d961a3a397"
      },
      "source": [
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 6s 20ms/step - loss: 0.6892 - binary_accuracy: 0.5856 - val_loss: 0.6826 - val_binary_accuracy: 0.6838\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.6747 - binary_accuracy: 0.6978 - val_loss: 0.6620 - val_binary_accuracy: 0.7502\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.6491 - binary_accuracy: 0.7516 - val_loss: 0.6307 - val_binary_accuracy: 0.7880\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.6151 - binary_accuracy: 0.7798 - val_loss: 0.5934 - val_binary_accuracy: 0.8118\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.5775 - binary_accuracy: 0.8070 - val_loss: 0.5546 - val_binary_accuracy: 0.8296\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.5388 - binary_accuracy: 0.8286 - val_loss: 0.5164 - val_binary_accuracy: 0.8472\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.5032 - binary_accuracy: 0.8424 - val_loss: 0.4805 - val_binary_accuracy: 0.8610\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.4681 - binary_accuracy: 0.8608 - val_loss: 0.4473 - val_binary_accuracy: 0.8728\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.4373 - binary_accuracy: 0.8720 - val_loss: 0.4171 - val_binary_accuracy: 0.8820\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.4089 - binary_accuracy: 0.8794 - val_loss: 0.3899 - val_binary_accuracy: 0.8906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evvWnjgmxhdB",
        "outputId": "a13d9e32-6483-4836-dfce-a37e38f0c860"
      },
      "source": [
        "# Evaluate on test set\n",
        "loss, accuracy = model.evaluate(test_ds)\n",
        "\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4612 - binary_accuracy: 0.8243\n",
            "Loss:  0.4611881971359253\n",
            "Accuracy:  0.8242800235748291\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}